{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Task - Predicting LOS using window and PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the necessary imports..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import lag, col, avg\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define necessary PySpark env variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-17-openjdk-amd64'\n",
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-21-openjdk-21.0.3.0.9-1.fc40.x86_64/'\n",
    "os.environ['SPARK_LOCAL_IP'] = '127.0.0.1'\n",
    "os.environ['SPARK_MASTER_HOST'] = 'localhost'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the spark session..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/16 11:40:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/16 11:40:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Setup\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.host\",\"127.0.0.1\") \\\n",
    "    .config(\"spark.driver.bindAddress\",\"127.0.0.1\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the previously processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- HADM_ID: integer (nullable = true)\n",
      " |-- SUBJECT_ID: integer (nullable = true)\n",
      " |-- ICUSTAY_ID: integer (nullable = true)\n",
      " |-- LOS: double (nullable = true)\n",
      " |-- SEQ_NUM: integer (nullable = true)\n",
      " |-- total_events: long (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- MULTIPLE_ADMISSIONS: boolean (nullable = true)\n",
      " |-- MULTIPLE_ICU_STAYS: boolean (nullable = true)\n",
      " |-- ADMISSION_TYPE: string (nullable = true)\n",
      " |-- AGE_ATE_ADMISSION: integer (nullable = true)\n",
      " |-- ADMITTIME: timestamp (nullable = true)\n",
      "\n",
      "+-------+----------+----------+------+-------+------------+------+-------------------+------------------+--------------+-----------------+-------------------+\n",
      "|HADM_ID|SUBJECT_ID|ICUSTAY_ID|   LOS|SEQ_NUM|total_events|GENDER|MULTIPLE_ADMISSIONS|MULTIPLE_ICU_STAYS|ADMISSION_TYPE|AGE_ATE_ADMISSION|          ADMITTIME|\n",
      "+-------+----------+----------+------+-------+------------+------+-------------------+------------------+--------------+-----------------+-------------------+\n",
      "| 192988|       295|    274998|0.9057|      2|        1246|     F|              false|             false|      ELECTIVE|               61|2176-03-06 12:30:00|\n",
      "| 160235|      2791|    293653|1.3653|      4|         732|     F|               true|              true|     EMERGENCY|               74|2120-04-25 17:04:00|\n",
      "| 135423|      2556|    298783| 0.705|      9|         736|     M|              false|             false|     EMERGENCY|               62|2173-02-20 23:57:00|\n",
      "| 144907|      4496|    250725|1.4628|      5|        1446|     M|              false|             false|     EMERGENCY|               69|2165-09-23 13:59:00|\n",
      "| 192401|      2225|    285710|7.5586|     19|       23668|     M|              false|             false|     EMERGENCY|               66|2129-10-24 17:04:00|\n",
      "+-------+----------+----------+------+-------+------------+------+-------------------+------------------+--------------+-----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = \"dataset/DS.parquet\"\n",
    "\n",
    "ds = spark.read.format(\"parquet\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .load(file_path)\n",
    "\n",
    "ds.printSchema()\n",
    "ds.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a window, and weÂ´ll order the window by admission time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_spec = Window.orderBy(col('ADMITTIME')).rowsBetween(-7, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the lag function to look at previous records of LOS, as this can potentially provide some context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<'CAST(lag(LOS, 2, NULL) OVER (ORDER BY ADMITTIME ASC NULLS FIRST ROWS BETWEEN -7 FOLLOWING AND CURRENT ROW) AS DOUBLE) AS avg_los_past_3'>\n"
     ]
    }
   ],
   "source": [
    "#WIP - \n",
    "avg_los_past_3 = lag('LOS', 2).over(window_spec).cast('double').alias('avg_los_past_3')\n",
    "\n",
    "print(avg_los_past_3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
